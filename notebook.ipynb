{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2604b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85e5611d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kaggle.api.authenticate()\n",
    "# kaggle.api.dataset_download_files('omkargurav/face-mask-dataset',unzip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0cdaf6e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs Available: []\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"GPUs Available:\", tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17a57749",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_process(img):\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)      # Convert BGR to RGB\n",
    "    img = cv2.resize(img, (256, 256))               # Resize to model input\n",
    "    img = img / 255.0                                # Normalize\n",
    "    img = np.expand_dims(img, axis=0)               # Add batch dimension\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4da0cc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(image):\n",
    "    image=image_process(image)\n",
    "    model = keras.models.load_model('face_mask_model.keras')\n",
    "    pred = model.predict(image)\n",
    "    print(pred)\n",
    "\n",
    "    # Convert to label\n",
    "    label = \"with_mask\" if pred[0][0] < 0.5 else \"without_mask\"\n",
    "    print(\"Predicted label:\", label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6aeb2df4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 E:\\Project\\FaceMask\\data\\without_mask\\without_mask_75.jpg: 640x640 1 face, 110.4ms\n",
      "Speed: 27.7ms preprocess, 110.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254ms/step\n",
      "[[          1]]\n",
      "Predicted label: without_mask\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"yolov8nfa.pt\")   # community face model\n",
    "results = model(r\"E:\\Project\\FaceMask\\data\\without_mask\\without_mask_75.jpg\")\n",
    "\n",
    "\n",
    "predict_image(results[0].orig_img)\n",
    "\n",
    "results[0].show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
